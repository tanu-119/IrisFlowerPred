{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Iris Flower Classification"
      ],
      "metadata": {
        "id": "VjInPXKmI-bG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Importing Required Libraries"
      ],
      "metadata": {
        "id": "YJ7k-5ICUYJz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n"
      ],
      "metadata": {
        "id": "nBuWxYe2UX3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Load the Dataset:\n",
        "\n",
        "This dataset contains 4 numerical features and a target column species representing 3 flower types."
      ],
      "metadata": {
        "id": "jymse7LPUdPJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/IRIS.csv')\n"
      ],
      "metadata": {
        "id": "pbnPm9ImUxNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Handle Missing Values\n",
        "\n",
        "If there are missing values in the numerical columns, we fill them using the column mean.\n",
        "\n",
        "For categorical column (species), we fill missing values using the most frequent value (mode)."
      ],
      "metadata": {
        "id": "luNaGTAYUzsx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.fillna(df.mean(numeric_only=True))\n",
        "if df['species'].isnull().sum() > 0:\n",
        "    df['species'] = df['species'].fillna(df['species'].mode().iloc[0])"
      ],
      "metadata": {
        "id": "o0aFjU2YU3Ng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Split Features and Target\n",
        "\n",
        "We separate:\n",
        "\n",
        "X: input features (sepal and petal measurements)\n",
        "\n",
        "y: target labels (species type)\n",
        "\n"
      ],
      "metadata": {
        "id": "D-_OJtttU4Vu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop('species', axis=1)\n",
        "y = df['species']\n"
      ],
      "metadata": {
        "id": "nRzpyGB5VFmN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Split Dataset into Training and Testing\n",
        "\n",
        "We split the dataset into:\n",
        "\n",
        "80% training data\n",
        "\n",
        "20% testing data\n",
        "random_state=42 ensures reproducibility."
      ],
      "metadata": {
        "id": "lWeMT6w2VNCr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "xBWOg2tHVPc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Standardize the Features\n",
        "\n",
        "We scale the features so they all have mean = 0 and standard deviation = 1, which improves model performance"
      ],
      "metadata": {
        "id": "YGtSspiIVXTe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n"
      ],
      "metadata": {
        "id": "g7HhPO3BVaC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Define and Train Multiple Models\n",
        "\n",
        "We define a dictionary containing six different classification models to compare their performance on the same data."
      ],
      "metadata": {
        "id": "yqF5La8_VhyH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(max_iter=200),\n",
        "    'KNN': KNeighborsClassifier(),\n",
        "    'SVM': SVC(),\n",
        "    'Random Forest': RandomForestClassifier(random_state=42),\n",
        "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
        "    'Naive Bayes': GaussianNB()\n",
        "}\n"
      ],
      "metadata": {
        "id": "YnY6gCEGVlWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Evaluate Model Accuracy\n",
        "\n",
        "We train each model and evaluate it using accuracy score. This helps us identify which model performs best on the test data."
      ],
      "metadata": {
        "id": "SM_g77AXVpqx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"ðŸ“Š Model Performance Summary:\\n\")\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    print(f\" {name}: {acc:.4f} accuracy\")\n"
      ],
      "metadata": {
        "id": "OpwXjczHV6aZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Predict on New Input\n",
        "\n",
        "We give a new flower's measurements as input and use the trained Random Forest model to predict its species. The input is scaled using the same StandardScaler used earlier."
      ],
      "metadata": {
        "id": "Zg0Rik97V9Fa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_input = [[5.8, 2.6, 4, 1.2]]\n",
        "new_input_scaled = scaler.transform(new_input)\n",
        "best_model = models['Random Forest']\n",
        "prediction = best_model.predict(new_input_scaled)\n",
        "print(f\"\\nðŸŒ¸ Predicted species for input {new_input[0]}: {prediction[0]}\")\n"
      ],
      "metadata": {
        "id": "oyG8H_BLVr-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hf3ZcmeQVX7P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}